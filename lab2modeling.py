# -*- coding: utf-8 -*-
"""Lab 2_Hannah_Samuel

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19gUlLSyXtuGssugCcK0VEk8qD0TOi7Qc

# Lab 2

In Lab 2, we will be coding Linear and Logistic regression using only Numpy! You will also be asked to use what you know about gradient descent to tweak the algorithms for better results. While teams should collaborate and help each other, each member of a group should complete their own code.

This skeleton is intended to be somewhat sparse in order to give you the opportunity to become familiar with the intuition behind gradient descent and to make you very familiar with Numpy. Please reach out to us for any conceptual/mathematical questions or if you are stuck on something and need a hint - we don't want you spending hours on this!

If you are unfamiliar with Numpy, don't worry! There are a ton of great resources on it and the its documentation is very well-written (*cough cough* OpenCV). You can figure our how to do most things with a simple Google Search, but here are some functions, operators, etc. that I found useful in this lab:

    .dot() and @, .astype(), .T, unique(), mean(), sum(), inv(), pinv(), reshape(), vstack(), hstack(), .unique(), .concatenate(), .shape(), .any()

### Some notes on using Colab

If you've never used Colab before, this section is for you! Some things to note:

* The different boxes in this document are segments of Python code. Many of them contain errors and won't work if you try to run them right away (using the play button on the left). You need to fill in the blanks to make them work!

* If you update a block of code, even if you re-run it, you must also re-run all the blocks after it up to the point where you're currently working. They don't run themselves!
"""

import numpy as np
import csv
from numpy.core.memmap import dtype
import matplotlib.pyplot as plt

# You may use these sklearn tools in your implementation, but no others.
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle

from google.colab import drive
drive.mount('/content/drive/')

WEATHER_PATH = '/content/drive/MyDrive/weatherHistory.csv'
data = np.loadtxt(WEATHER_PATH, delimiter=",", dtype=str)
data = data[:,1:-1]
header = data[0]
data = data[1:]

"""##Part 1: Single line fit!

In this part of the lab, you will be using only the humidity data to estimate the temperature using linear regression. Then we well compare the results of a single feature linear regression with the closed form solution. Experiment with the learning rate and number of iterations and try to find the optimal learning rate for 40 iterations (we got it to 59.5).
"""

# Right now, the data is in cone large matrix. Seperate out x as the humidity
# and y as the temperature.

x = data[:, 4]
y = data[:, 2]
x = x.astype('float')
y = y.astype('float')
print(x)
print(y)

# Code the mean squared error function given x, y, a, and b.
def MSE(x, y, a, b):
  # yhat = ax + b
  mse_arr = [] # empty array
  for i in range(len(x)): #iterate through x array
    yhat = (a*x[i]) + b # calculate the predicted y
    mse_arr.append((y[i]-yhat)**2) # subtract it from actual y and square it; add it to the predicted array
  mse = np.mean(mse_arr)
  return mse
# Code the gradient descent function. This will return the new values of a and b
# after the gradient has been calculated and the learning rate has been applied.
def grad_des(x, y, a, b):
  # yhat = ax + b
  alpha = 0.6155
  grad_arr_a = [] # empty array
  for i in range(len(x)): #iterate through x array
    g_a = (-2*y[i]*x[i]) + ((2*a)*(x[i]**2)) + (2*x[i]*b)
    grad_arr_a.append(g_a)
  grad_a = np.mean(grad_arr_a)
  a2 = a - (alpha * grad_a)
  grad_arr_b = [] # empty array
  for i in range(len(x)): #iterate through x array
    g_b = (-2*y[i]) + (2*x[i]*a) + (2*b)
    grad_arr_b.append(g_b)
  grad_b = np.mean(grad_arr_b)
  b2 = b - (alpha * grad_b)
  return a2, b2

# Initialize a and b.
a = 2
b = 0.15
lr = 0.01 # Set the learning rate.

losses = []
for i in range(40):
  losses.append(MSE(x, y, a, b))
  # Update a and b using the values from your gradient descent function.
  a,b = grad_des(x,y,a,b)
print(f"Final Training Loss: {losses[-1]}")
plt.plot(losses)
plt.title("single feature loss over time")

"""This is your **loss graph**. Hang onto it, because you'll need it later for the checkoff.

In addition, remember what we taught you guys about how your training should improve the loss: it should decay towards a minimum as the gradient descent iterations continue. Pay attention to the y-axis here, which indicates the loss. If your error blows up towards infinity or doesn't decrease very quickly, you should be able to recognize and rectify the issue with your hyperparameters!
"""

# Let's take a look at what our line of best fit looks like!
plt.scatter(x, y)
plt.plot(x, a*x+b, color='orange')

# Now let's find the true optimal solution using the closed form equation. Use
# np.polyfit or other such functions only to check your work.
# Don't forget what you need to add to the X matrix in order for the closed form
# to work!
from numpy.linalg import inv, pinv
one_col =  np.ones(len(x))
X = np.vstack((x, one_col)).T # Add column of ones
x_transpose = X.T
x_transpose_times_x = x_transpose @ X
inverse = inv(x_transpose_times_x)
tranpose_time_y = x_transpose @ y
th = tranpose_time_y @ inverse  # Closed form solution for theta
a1, b1 = th

# Compare our closed form with our gradient descent. The closed form solution
# should be the same thing as the result of polyfit.

a2, b2 = np.polyfit(x, y, 1)
print(f"Grad Desc:   a: {a} b: {b} MSE: {MSE(x, y, a, b)}")
print(f"Closed form: a: {a1} b: {b1} MSE: {MSE(x, y, a1, b1)}")
print(f"Poly Fit:    a: {a2} b: {b2}")

plt.scatter(x, y)
plt.plot(x, a*x+b, color='orange')
plt.plot(x, a1*x+b1, color='yellow')
plt.title("closed and gd best fit lines")

"""To get checked off for this part, submit screenshots of the following in the submission form:
- loss graph
- the graph with your 2 best fit lines
- the final MSE for your gradient descent and closed form solutions
- your grad_des function

##Part 2: Multiple input features

In this part we will modify our gradient descent function to accept all of the possible input features. This will require converting the precipitation type and weather summaries to one-hot encodings (see slides 20-25 and 33). Then we will have to change our equations to be in matrix notation.
"""

# First, lets get our x and y data one-hot encoded.
# hot_X should be the data where the categorical fields are converted into
#     one-hot encodings (temperature data excluded).
# As a sanity check, the dimensions should be (96453, 38).
# hot_y should still just be the temperature data.
summary_data = data[:, 0]
precipitation_data = data[:, 1]
temperature_data = data[:, 2]
other_data = data[:, 3:]

#print(summary_data)
#print(precipitation_data)
#print(temperature_data)
#print(daily_summary_data)
#print(other_data)



summary_categories = np.unique(summary_data)
precipitation_categories = np.unique(precipitation_data)
print(summary_categories)
print(len(summary_categories))

print(precipitation_categories)
print(len(precipitation_categories))

summary_encoded = []

for value in summary_data:
    row_sum = []
    for category in summary_categories:
        if value == category:
            row_sum.append(1)
        else:
            row_sum.append(0)
    summary_encoded.append(row_sum)

summary_encoded = np.array(summary_encoded)
#print("One-hot encoding for summary_data:")
#print(summary_encoded)

precipitation_encoded = []

for value in precipitation_data:
    row_precep = []
    for category in precipitation_categories:
        if value == category:
            row_precep.append(1)
        else:
            row_precep.append(0)
    precipitation_encoded.append(row_precep)

precipitation_encoded = np.array(precipitation_encoded)



other_data_numeric = other_data.astype(float)
summary_encoded = summary_encoded.astype(float)
precipitation_encoded = precipitation_encoded.astype(float)

hot_X = np.hstack((summary_encoded, precipitation_encoded,  other_data))
#hot_X = np.hstack((summary_encoded, precipitation_encoded,  other_data))

hot_X = np.hstack((np.ones((hot_X.shape[0], 1)), hot_X))  # Add bias term

hot_X = hot_X.astype(float)  # Convert all elements to float

hot_y = temperature_data.astype(float)
#hot_y = hot_y.reshape(-1, 1)

#print("Final hot_X:")
#print(hot_X)
#print(hot_y)
print(hot_X[0])
print(len(hot_X[0]))

print(hot_X.shape)

"""Now update your gradient descent and Mean Squared Error function to be able to learn from multiple features. See how low you can get the error after 40 iterations.

You may notice a higher error than we got in part 1, especially when compared with an extrememly low closed form error. Think about why this may be the case and what hyperparameters you can tune to improve this.
"""

def grad_des2(X, y, theta):
  #Code!
   #alpha = 0.0000000199
   #alpha = 0.0000009
   #alpha = 0.000000895
   #alpha = 0.0000001
   #y = y.reshape(-1,1)
   #theta = theta.reshape(-1, 1)

   alpha = 0.00000089
   n = len(X)  # Number of samples
   yhat = X @ theta
   grad = -(2/n) * ((X.T @ y)  - (X.T @ X @ theta))
   g_theta = theta - (alpha * grad)
   return g_theta

def MSE2(x, y, theta):

  n = len(x)  # Number of samples
  #y = y.reshape(-1, 1)
  #theta = theta.reshape(-1, 1)
  yhat = x @ theta
  residual = y - yhat

  #mse = (1 / n) * np.sum(residual**2)
  mse = (1 / n) *((residual.T) @ (residual))
  return mse

theta = np.zeros(len(hot_X[0]))

losses = []
#losses.append(MSE2(hot_X, hot_y, theta))

for i in range(40):
  losses.append(MSE2(hot_X, hot_y, theta))
  theta = grad_des2(hot_X, hot_y, theta)  # Update theta using gradient descent
print(f"Final Training Loss: {losses[-1]}")
plt.plot(losses)
plt.title("Multi feature loss over time")

theta2 = np.zeros(len(hot_X[0]))


# Now solve for theta using the closed form and compare your final training loss between
# the closed form and regression solution
#print(hot_X)

to_invert = hot_X.T @ (hot_X)
intverted = np.linalg.pinv(to_invert)
thet = intverted.dot(hot_X.T @ (hot_y))
th2 = thet #find theta using closed form

closed = MSE2(hot_X, hot_y, th2)
print(closed)
print(grad_des2(hot_X, hot_y, th2))
print(MSE2(hot_X, hot_y, grad_des2(hot_X, hot_y, th2)))

"""As you can (probably) see, the gradient descent error is worse than the single input version and much worse than the closed form solution. Think about why this is and how can improve it (hint: we talked about this technique in our lecture). Copy your code above into the cell below to make any modifications to improve your gradient descent!"""

def grad_des3(X, y, theta):
   alpha = 0.0000002
   n = len(X)  # Number of samples
   yhat = X @ theta
   grad = -(2/n) * ((X.T @ y)  - (X.T @ X @ theta))
   g_theta = theta - (alpha * grad)
   return g_theta


def minibatch(X,y,batch_size):
  #X,y = shuffle(X,y)
  mini_batches = []
  #iterate through X data set and grab smaller subset of the data with the size of batch_size
  for i in range(0, len(X), batch_size):
    X_batch = X[i:i + batch_size]
    y_batch = y[i:i + batch_size]
    mini_batches.append((X_batch, y_batch))

  return mini_batches  # Return the list of mini-batches
theta = np.zeros((len(hot_X[0])))
batch_size = 30
losses = []
for i in range(40):

  mini_batches = minibatch(hot_X, hot_y, batch_size)  # Get mini-batches
  for X_batch, y_batch in mini_batches: #perform gradient descent on each batch
      theta = grad_des3(X_batch, y_batch, theta) #update paramters based on errors calculated
  losses.append(MSE2(hot_X, hot_y, theta))


print(f"Final Training Loss: {losses[-1]}")
plt.plot(losses)
plt.title("Modified multi feature loss over time")

"""I tried using min batch gradient descent which is a technique that focuses on computing the gradient on smaller subsets of the total dataset. Computing on smaller datasets accounts for more variance accross multiple features and speeds up convergence. I also updated the learning rate and batch size till the curve resembled a gradient descent

To get checked off for this part, submit screenshots of the following in the submission form:
- both of your loss graphs
- closed form error
- your code for both GD algorithms
- an explaination of what you changed and why

##Part 3: Logistic Regression and K-fold Cross Validation



In this part of the lab you will be esimating if someone will suffer a heart attack in the next 10 years based on health statistics. This time, we will be using K-fold cross validation to determine the viability of our model. In lecture, we did not give you the full equation for logistic regression, I suggest deriving it before starting that part of the lab. Try to do it yourself! (The answer should be **simple** - if you are coding a disgusting equation, that is wrong and you should stop.)
"""

HAM_PATH ='/content/drive/MyDrive/framingham.csv' # Add the path to your health data here
health_data = np.loadtxt(HAM_PATH, delimiter=",", dtype=str)

# But wait! The data is not complete! Take a look to see what is wrong with it
# and remove any offending datapoints (rows) - this is the "cleaning" stage of
# the ML pipeline.
# Challange: do this in one line.
health_data = health_data[~(health_data == 'NA').any(axis=1)]
# clean health data!
#print(health_data[15])

# Create your X and Y data and clean it! Binarize the assigned-sex-at-birth
# column and add the bias term to your X data

health_x = health_data[1:,1:-1]
health_y = health_data[1:,-1]

#Clean it up!
bias_term = np.ones((health_x.shape[0], 1))
health_x = np.hstack([ health_x, bias_term])  # Add the column of ones to the left

health_x = health_x.astype('double')
health_y = health_y.astype('double')
print(health_x)
print(health_x.shape)

# Separate your training data into 5 folds for cross validation

X_train, X_test, y_train, y_test = train_test_split(health_x, health_y, test_size=0.2, random_state=0)
X_train, y_train = shuffle(X_train, y_train)
k = 5
size_of_fold = len(X_train) // 5

X_folds = []
y_folds = []

for i in range(k):
  beginning_of_fold = i * size_of_fold # accesses the position at which each row of each fold begins
  if i == k-1:
    end_of_fold = len(X_train)
  else:
    end_of_fold = (i+1)*size_of_fold # the next element where the we want the fold to stop
  X_folds.append(X_train[beginning_of_fold:end_of_fold])
  y_folds.append(y_train[beginning_of_fold:end_of_fold])

# A quick check:
for fold in range(k):
  print(X_folds[fold].shape)
  print(y_folds[fold].shape)
  print(len(X_folds))

# Now lets code all of our relevant equations.

def sigmoid(x):
  return 1 / (1 + (np.exp(-x)) ) # this is yhat

def accuracy(X, y, theta):
  # num of correct prediction / total predictions
  y_hat = sigmoid(X @ theta)
  predictions = []
  for prediction in y_hat:
    if prediction >= 0.5:
      predictions.append(1)
    else:
      predictions.append(0)
  counter = 0
  for i in range(len(predictions)):
    if predictions[i] == y[i]:
      counter += 1
  accuracy = counter / len(predictions)
  return accuracy

def cross_entropy_loss(X, y, theta): # this is loss function (L(y,yhat))
  exponent = X @ theta # input to getting yhat
  yhat = sigmoid(exponent) # calculating yhat
  loss = (-y * np.log(yhat)) - (1-y)*(np.log(1-yhat)) # using yhat to create a loss value
  return np.mean(loss)

def log_grad_desc(X, y_hat, y): # this is the gradient function (dL/dtheta)
  #dl_dyhat = (-y/y_hat) + ((1-y) / (1-y_hat))
  #dyhat_dxthet = y_hat * (1-y_hat)
  #dl_dxtheta = dl_dyhat * dyhat_dxthet
  #dl_dtheta = X.T @ dl_dxtheta # use X.T instead of X to match dimensions
  # simplifies to this:
  grad_L = X.T @ (y_hat - y)
  grad_L = grad_L / len(y)
  return grad_L

# Now lets validate our model. Use the validation error to tune your
#hyperparameters. Also, compare your validation and training errors

lr = 0.001 # Set learning rate

val_losses = []
train_losses = []
for fold in range(k):
  theta = np.random.randn(health_x.shape[1]) # Reinitialize theta

  # Set your validation and training datasets
  X_val = X_folds[fold] # pick our validation fold
  y_val = y_folds[fold]


  X_train = np.concatenate(X_folds[:fold] + X_folds[fold+1:]) # grabbing all the other folds except that val fold and use the other folds for training
  y_train = np.concatenate(y_folds[:fold] + y_folds[fold+1:])

  for i in range(5000):
    # Do gradient descent
    theta -= log_grad_desc(X_train, sigmoid(X_train @ theta), y_train) * lr

  val_losses.append(cross_entropy_loss(X_val, y_val, theta))
  train_losses.append(cross_entropy_loss(X_train, y_train, theta))


print(f"train_losses: {sum(train_losses)/len(train_losses)}")
print(f"val_losses: {sum(val_losses)/len(val_losses)}")

# Training - once you have tuned your hyperparameters, train your model once
# more on all the training data and then test it on the test dataset

lr = 0.001
theta = np.random.randn(health_x.shape[1])

for i in range(5000):
  #Gradient Descent
  y_hat = sigmoid(X_train @ theta)
  theta -= log_grad_desc(X_train,y_hat,y_train) * lr # Perform gradient descent


print(f"Testing Accuracy: {accuracy(X_test, y_test, theta)}")

"""To be checked off for this part, submit screenshots of the following in the submission form: your code for gradient descent and the resulting training, validation, and testing losses.

Once you submit the form, let us know in your team group chats so we can give you checkoff questions!
"""